{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cafcec-d5d8-4ac0-968f-8c6e530bed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245b358-40d0-47d0-a28c-324fe80f3da5",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545eaf75-528f-4aa9-901f-99f4562b2aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_path = \"data/image_path/\"\n",
    "sure_image_path = \"data/sure image/\"\n",
    "device = \"cuda\"\n",
    "sure_vector_path = \"data/sure image/sure_image_vector.dict\"\n",
    "label_file = \"data/df.csv\"\n",
    "target_path = \"data/dataset/\"\n",
    "reserved_suffix = [\"jpeg\", \"png\"]\n",
    "\n",
    "\"\"\"\n",
    "最小距离为0.75的要至少占比50%\n",
    "最小距离为0.55的要至少占比100%\n",
    "\"\"\"\n",
    "rule_list = [\n",
    "    {\"percentage\": .5, \"min_distance\": .75},\n",
    "    {\"percentage\": 1., \"min_distance\": .55},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678ed7b-6376-4dbe-9c27-d33a2173d91e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74165d2d-1cde-4b81-9688-9720ea402906",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(364),\n",
    "    T.CenterCrop((364, 364)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8b382c-50a5-48d0-9faa-cfc953593674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhy/NanShan_animal/dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/zhy/NanShan_animal/dinov2/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/zhy/NanShan_animal/dinov2/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('dinov2', 'dinov2_vitl14_lc', source=\"local\", pretrained=True)\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade99d8-265e-47f9-b2fd-ecb941cd9773",
   "metadata": {},
   "source": [
    "# Sure Image Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6701aaaf-fcd3-43c4-bf1b-eb6c05b44b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = sorted([\n",
    "    path.split(\"/\")[-1]\n",
    "    for path in glob.iglob(f\"{sure_image_path}/*\")\n",
    "    if os.path.isdir(path)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddfe306-3096-46a3-bfac-3a360a0d6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sure_image_vector = {}\n",
    "if sure_vector_path is None:\n",
    "    with torch.no_grad():\n",
    "        for cls in classes:\n",
    "            cache = []\n",
    "            img_path = glob.glob(f\"{sure_image_path}/{cls}/*\")\n",
    "            for i in range(0, len(img_path), batch_size):\n",
    "                img = [\n",
    "                    transform(Image.open(path).convert(\"RGB\"))\n",
    "                    for path in img_path[i: i + batch_size]\n",
    "                ]\n",
    "                x = torch.stack(img).to(device)\n",
    "                cache.append(model(x).cpu())\n",
    "\n",
    "            sure_image_vector[cls] = torch.cat(cache)\n",
    "    torch.save(sure_image_vector, \"data/sure image/sure_image_vector.dict\")\n",
    "else:\n",
    "    sure_image_vector = torch.load(sure_vector_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45518ad3-6978-4fad-941c-d94b06b4f5e0",
   "metadata": {},
   "source": [
    "# Similarigy Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939fa12a-42d6-4f7b-8db8-fd151907e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarigy(A, B):\n",
    "    \"\"\" 计算向量间的余弦值\n",
    "    Args:\n",
    "        A (Tensor): shape->(N, D)\n",
    "        B (Tensor): shape->(M, D)\n",
    "        \n",
    "    Return: shape->(N, M)\n",
    "    \"\"\"\n",
    "    A = A[:, None, :]\n",
    "    B = B[None, :, :]\n",
    "    return (\n",
    "        (A * B).sum(dim=-1) / \n",
    "        (A.pow(2).sum(dim=-1).sqrt() * B.pow(2).sum(dim=-1).sqrt())\n",
    "    )\n",
    "\n",
    "def filter_distance_image(vector, rule=None):\n",
    "    \"\"\" 根据规则筛选向量\n",
    "    Args:\n",
    "        vector (Tensor): 距离向量(M, N), N为目标图片数量, M为源图片数量\n",
    "        rule (List[dict]): 筛选规则, 距离向量应满足所有规则要求才能拷贝到所对应目录,\n",
    "            dict应含有`percentage` (所占目标向量总数的百分比)和`min_distance` (最小距离大小)\n",
    "    \"\"\"\n",
    "    if not rule:\n",
    "        raise \"未指定任何规则信息\"\n",
    "    \n",
    "    target_count = vector.size(1)\n",
    "    cache_vector = torch.ones(vector.size(0))\n",
    "    for r in rule:\n",
    "        cache_vector *= (\n",
    "            (\n",
    "                (vector > r[\"min_distance\"]).sum(-1) /\n",
    "                target_count\n",
    "            ) >= r[\"percentage\"]\n",
    "        )\n",
    "        \n",
    "    return cache_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3abf76d-3494-4184-afc6-d26bda9987ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除不明后缀名\n",
    "df = pd.read_csv(label_file)\n",
    "df[\"file_suffix\"] = df.file_name.str.split(\".\").str[-1]\n",
    "df = df[df[\"file_suffix\"].isin(reserved_suffix)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3acae504-e6ed-4a0d-8450-780b000ffeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东方蝙蝠\t\t源图片数量：971\t 筛选后图片数量: 35\n",
      "乌鸫\t\t源图片数量：873\t 筛选后图片数量: 838\n",
      "凤头鹰\t\t源图片数量：922\t 筛选后图片数量: 806\n",
      "北社鼠\t\t源图片数量：38\t 筛选后图片数量: 5\n",
      "北红尾鸲\t\t源图片数量：914\t 筛选后图片数量: 892\n",
      "华南兔\t\t源图片数量：518\t 筛选后图片数量: 21\n",
      "喜鹊\t\t源图片数量：888\t 筛选后图片数量: 488\n",
      "家燕\t\t源图片数量：864\t 筛选后图片数量: 806\n",
      "小䴙䴘\t\t源图片数量：789\t 筛选后图片数量: 772\n",
      "小星头啄木鸟\t\t源图片数量：529\t 筛选后图片数量: 279\n",
      "山斑鸠\t\t源图片数量：889\t 筛选后图片数量: 859\n",
      "戴胜\t\t源图片数量：967\t 筛选后图片数量: 962\n",
      "斑姬啄木鸟\t\t源图片数量：879\t 筛选后图片数量: 825\n",
      "普通翠鸟\t\t源图片数量：900\t 筛选后图片数量: 889\n",
      "松雀鹰\t\t源图片数量：910\t 筛选后图片数量: 699\n",
      "林雕\t\t源图片数量：783\t 筛选后图片数量: 435\n",
      "树莺\t\t源图片数量：864\t 筛选后图片数量: 815\n",
      "棕背伯劳\t\t源图片数量：944\t 筛选后图片数量: 936\n",
      "灰喜鹊\t\t源图片数量：937\t 筛选后图片数量: 891\n",
      "灰树鹊\t\t源图片数量：472\t 筛选后图片数量: 292\n",
      "灰脸鵟鹰\t\t源图片数量：684\t 筛选后图片数量: 444\n",
      "珠颈斑鸠\t\t源图片数量：899\t 筛选后图片数量: 864\n",
      "画眉\t\t源图片数量：882\t 筛选后图片数量: 714\n",
      "白头鹎\t\t源图片数量：861\t 筛选后图片数量: 847\n",
      "白鹭\t\t源图片数量：895\t 筛选后图片数量: 878\n",
      "竹鸡\t\t源图片数量：888\t 筛选后图片数量: 639\n",
      "红嘴蓝鹊\t\t源图片数量：897\t 筛选后图片数量: 875\n",
      "红头长尾山雀\t\t源图片数量：910\t 筛选后图片数量: 850\n",
      "红胁蓝尾鸲\t\t源图片数量：892\t 筛选后图片数量: 849\n",
      "红腹松鼠\t\t源图片数量：901\t 筛选后图片数量: 339\n",
      "红隼\t\t源图片数量：899\t 筛选后图片数量: 873\n",
      "绿头鸭\t\t源图片数量：838\t 筛选后图片数量: 745\n",
      "褐家鼠\t\t源图片数量：806\t 筛选后图片数量: 420\n",
      "赤腹鹰\t\t源图片数量：867\t 筛选后图片数量: 604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhy/miniconda3/envs/torch2.0/lib/python3.9/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "远东刺猬\t\t源图片数量：402\t 筛选后图片数量: 194\n",
      "野猪\t\t源图片数量：869\t 筛选后图片数量: 641\n",
      "银喉长尾山雀\t\t源图片数量：914\t 筛选后图片数量: 885\n",
      "长尾缝叶莺\t\t源图片数量：742\t 筛选后图片数量: 495\n",
      "雀鹰\t\t源图片数量：938\t 筛选后图片数量: 806\n",
      "雉鸡\t\t源图片数量：837\t 筛选后图片数量: 763\n",
      "鹊鸲\t\t源图片数量：896\t 筛选后图片数量: 843\n",
      "麻雀\t\t源图片数量：873\t 筛选后图片数量: 685\n",
      "黄喉鹀\t\t源图片数量：934\t 筛选后图片数量: 852\n",
      "黄眉柳莺\t\t源图片数量：873\t 筛选后图片数量: 612\n",
      "黄鼬\t\t源图片数量：916\t 筛选后图片数量: 183\n",
      "黑水鸡\t\t源图片数量：866\t 筛选后图片数量: 854\n",
      "黑翅短脚鹎\t\t源图片数量：334\t 筛选后图片数量: 53\n",
      "黑脸噪鹛\t\t源图片数量：788\t 筛选后图片数量: 508\n",
      "黑鸢\t\t源图片数量：873\t 筛选后图片数量: 555\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for cls in classes:\n",
    "        target_vector = sure_image_vector[cls]\n",
    "        cache = []\n",
    "        img_path = df.query(f\"name == '{cls}'\").file_name.to_list()\n",
    "        for i in range(0, len(img_path), batch_size):\n",
    "            img = [\n",
    "                transform(Image.open(os.path.join(image_path, path)).convert(\"RGB\"))\n",
    "                for path in img_path[i: i + batch_size]\n",
    "            ]\n",
    "            x = torch.stack(img).to(device)\n",
    "            cache.append(model(x).cpu())\n",
    "\n",
    "        cls_vector = torch.cat(cache)\n",
    "        distance = cosine_similarigy(cls_vector, target_vector)\n",
    "        if not os.path.exists(os.path.join(target_path, cls)):\n",
    "            os.mkdir(os.path.join(target_path, cls))\n",
    "        \n",
    "        filter_vector = filter_distance_image(distance, rule_list)\n",
    "        for flag, path in zip(filter_vector, img_path):\n",
    "            if flag == 1:\n",
    "                shutil.copy(\n",
    "                    os.path.join(image_path, path),\n",
    "                    os.path.join(target_path, cls, path)\n",
    "                )\n",
    "        print(f\"{cls}\\t\\t源图片数量：{distance.size(0)}\\t 筛选后图片数量: {int(filter_vector.sum())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "torch2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
